import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ –¥–∞–Ω–Ω–∏
def generate_data():
    """–ì–µ–Ω–µ—Ä–∏—Ä–∞ –ø—Ä–æ—Å—Ç–∏ –¥–∞–Ω–Ω–∏ –∑–∞ –ª–∏–Ω–µ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å–∏—è"""
    np.random.seed(42)
    torch.manual_seed(42)
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ X –¥–∞–Ω–Ω–∏ (–≤—Ö–æ–¥–Ω–∏ –¥–∞–Ω–Ω–∏)
    X = torch.linspace(0, 10, 100).reshape(-1, 1)
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ Y –¥–∞–Ω–Ω–∏ (—Ü–µ–ª–µ–≤–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏) —Å —à—É–º
    # Y = 2*X + 3 + —à—É–º
    true_slope = 2.0
    true_intercept = 3.0
    noise = torch.randn(100, 1) * 0.5
    y = true_slope * X + true_intercept + noise
    
    return X, y, true_slope, true_intercept

# –î–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞
class SimpleLinearModel(nn.Module):
    """–ú–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç –ª–∏–Ω–µ–µ–Ω –º–æ–¥–µ–ª"""
    def __init__(self):
        super(SimpleLinearModel, self).__init__()
        # –ï–¥–∏–Ω –ª–∏–Ω–µ–µ–Ω —Å–ª–æ–π: y = wx + b
        self.linear = nn.Linear(1, 1)
    
    def forward(self, x):
        return self.linear(x)

def train_model():
    """–û–±—É—á–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞"""
    print("üöÄ –ó–∞–ø–æ—á–≤–∞–º–µ –æ–±—É—á–µ–Ω–∏–µ—Ç–æ...")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏
    X, y, true_slope, true_intercept = generate_data()
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞
    model = SimpleLinearModel()
    
    # –î–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è—Ç–∞ –∑–∞ –∑–∞–≥—É–±–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    criterion = nn.MSELoss()  # –°—Ä–µ–¥–Ω–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω–∞ –≥—Ä–µ—à–∫–∞
    optimizer = optim.SGD(model.parameters(), lr=0.01)  # –°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ–Ω –≥—Ä–∞–¥–∏–µ–Ω—Ç–µ–Ω —Å–ø—É—Å–∫
    
    # –°–ø–∏—Å—ä–∫ –∑–∞ —Å—ä—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –∑–∞–≥—É–±–∏—Ç–µ
    losses = []
    
    # –û–±—É—á–µ–Ω–∏–µ
    num_epochs = 1000
    for epoch in range(num_epochs):
        # –ü—Ä–µ–¥–∏–∫—Ü–∏—è
        predictions = model(X)
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –∑–∞–≥—É–±–∞—Ç–∞
        loss = criterion(predictions, y)
        
        # –û–±—Ä–∞—Ç–Ω–æ —Ä–∞–∑–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
        optimizer.zero_grad()  # –ù—É–ª–∏—Ä–∞–Ω–µ –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∏—Ç–µ
        loss.backward()        # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∏—Ç–µ
        optimizer.step()       # –û–±–Ω–æ–≤—è–≤–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
        
        # –ó–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ –∑–∞–≥—É–±–∞—Ç–∞
        losses.append(loss.item())
        
        # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å–∞ –≤—Å–µ–∫–∏ 100 –µ–ø–æ—Ö–∏
        if (epoch + 1) % 100 == 0:
            print(f"–ï–ø–æ—Ö–∞ {epoch + 1}/{num_epochs}, –ó–∞–≥—É–±–∞: {loss.item():.4f}")
    
    return model, X, y, losses, true_slope, true_intercept

def visualize_results(model, X, y, losses, true_slope, true_intercept):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
    # –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
    learned_weight = model.linear.weight.item()
    learned_bias = model.linear.bias.item()
    
    print(f"\nüìä –†–µ–∑—É–ª—Ç–∞—Ç–∏:")
    print(f"–ò—Å—Ç–∏–Ω—Å–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: –Ω–∞–∫–ª–æ–Ω = {true_slope:.2f}, –æ—Ç—Å–µ—á–∫–∞ = {true_intercept:.2f}")
    print(f"–ù–∞—É—á–µ–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: –Ω–∞–∫–ª–æ–Ω = {learned_weight:.2f}, –æ—Ç—Å–µ—á–∫–∞ = {learned_bias:.2f}")
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∏
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # –ì—Ä–∞—Ñ–∏–∫–∞ 1: –î–∞–Ω–Ω–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    ax1.scatter(X.numpy(), y.numpy(), alpha=0.6, label='–î–∞–Ω–Ω–∏', color='blue')
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –º–æ–¥–µ–ª–∞
    with torch.no_grad():
        predictions = model(X)
        ax1.plot(X.numpy(), predictions.numpy(), 'r-', linewidth=2, label='–ú–æ–¥–µ–ª')
    
    # –ò—Å—Ç–∏–Ω—Å–∫–∞—Ç–∞ –ª–∏–Ω–∏—è
    true_line = true_slope * X.numpy() + true_intercept
    ax1.plot(X.numpy(), true_line, 'g--', linewidth=2, label='–ò—Å—Ç–∏–Ω—Å–∫–∞ –ª–∏–Ω–∏—è')
    
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_title('–õ–∏–Ω–µ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å–∏—è')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫–∞ 2: –ó–∞–≥—É–±–∞—Ç–∞ –ø—Ä–µ–∑ –≤—Ä–µ–º–µ—Ç–æ
    ax2.plot(losses)
    ax2.set_xlabel('–ï–ø–æ—Ö–∞')
    ax2.set_ylabel('–ó–∞–≥—É–±–∞ (MSE)')
    ax2.set_title('–ó–∞–≥—É–±–∞—Ç–∞ –ø—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ—Ç–æ')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('linear_regression_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nüíæ –ì—Ä–∞—Ñ–∏–∫–∏—Ç–µ —Å–∞ –∑–∞–ø–∞–∑–µ–Ω–∏ –∫–∞—Ç–æ 'linear_regression_results.png'")

def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéØ –î–æ–±—Ä–µ –¥–æ—à–ª–∏ –≤ –ø—ä—Ä–≤–∏—è PyTorch –ø—Ä–æ–µ–∫—Ç!")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ PyTorch —Ä–∞–±–æ—Ç–∏
    print(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"CUDA –Ω–∞–ª–∏—á–Ω–æ: {torch.cuda.is_available()}")
    
    # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª–∞
    model, X, y, losses, true_slope, true_intercept = train_model()
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
    visualize_results(model, X, y, losses, true_slope, true_intercept)
    
    print("\n‚úÖ –ü—Ä–æ–µ–∫—Ç—ä—Ç –∑–∞–≤—ä—Ä—à–∏ —É—Å–ø–µ—à–Ω–æ!")
    print("–¢–æ–≤–∞ –±–µ—à–µ –µ–ª–µ–º–µ–Ω—Ç–∞—Ä–µ–Ω –ø—Ä–∏–º–µ—Ä –∑–∞ –ª–∏–Ω–µ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å–∏—è —Å PyTorch.")

if __name__ == "__main__":
    main()
